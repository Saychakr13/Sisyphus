{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "# Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as skp\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# dr is the divide ratio. It divides the dataset into dr:1 ratio\n",
    "dr = 19\n",
    "\n",
    "# f_param is the timestep function\n",
    "f_param = 30\n",
    "\n",
    "# Parameters of the RNN\n",
    "num_of_middle_layers = 10\n",
    "middle_layer_units = 100\n",
    "middle_layer_dropouts = 0.001\n",
    "RNN_epochs = 300\n",
    "\n",
    "# Importing the training set\n",
    "dataset = pd.read_csv('nifty50twoyearsrecentdata.csv')\n",
    "\n",
    "cols = dataset.columns.tolist()\n",
    "\n",
    "# Dropping the effective date. Its not needed for now\n",
    "dataset = dataset.drop(cols[0], 1)\n",
    "k = len(dataset)\n",
    "\n",
    "cols = dataset.columns.tolist()\n",
    "\n",
    "# Now I will drop the base values. I want to work with real values\n",
    "for i in cols:\n",
    "    if i.find('(Base value)') != -1:\n",
    "        dataset = dataset.drop(i, 1)\n",
    "\n",
    "cols = dataset.columns.tolist()\n",
    "\n",
    "# Removing the nan or 0 values\n",
    "for i in cols:\n",
    "    for j in range(1, len(dataset)):\n",
    "        if dataset[i][j] == 0 or np.isnan(dataset[i][j]):\n",
    "            dataset[i][j] = dataset[i][j - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(pos):\n",
    "    print(\"\\n\\n!Achtung!\")\n",
    "    print(\"The following are the choices of indexes:\")\n",
    "    print(*cols, sep=\"\\n\")\n",
    "    print(\"The index chosen is: \")\n",
    "    print(cols[pos])\n",
    "    print(\"If not, adjust the variable pos correctly\")\n",
    "    print(\"pos should belong to [0, \" + str(len(cols)) + \")\")\n",
    "    print(\"\\n\\n\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Dividing the dataset into training set and testing set\n",
    "    dl = int((dr / (dr + 1)) * k)\n",
    "    training_set = dataset.iloc[0:dl, pos:(pos + 1)].values\n",
    "    testing_set = dataset.iloc[(dl - 1):, pos:(pos + 1)].values\n",
    "\n",
    "    # Feature Scaling\n",
    "    sc = skp.MinMaxScaler(feature_range=(0, 1))\n",
    "    training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "    # Creating a data structure with f_param timesteps and 1 output\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(f_param, len(training_set)):\n",
    "        x_train.append(training_set_scaled[i - f_param:i, 0])\n",
    "        y_train.append(training_set_scaled[i, 0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "    # Reshaping\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    #                              no of rows........timestep.........features\n",
    "\n",
    "    # Building the RNN\n",
    "\n",
    "    # Initialising the RNN\n",
    "    regressor = Sequential()\n",
    "\n",
    "    # Adding the first LSTM layer and some Dropout regularisation. Its the input layer\n",
    "    regressor.add(LSTM(units=70, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    regressor.add(Dropout(0.01))\n",
    "\n",
    "    # Adding the middle layers\n",
    "    for i in range(0, num_of_middle_layers):\n",
    "        regressor.add(LSTM(units=middle_layer_units, return_sequences=True))\n",
    "        regressor.add(Dropout(middle_layer_dropouts))\n",
    "\n",
    "    # Adding the penultimate LSTM layer and some Dropout regularisation\n",
    "    regressor.add(LSTM(units=70))\n",
    "    regressor.add(Dropout(0.01))\n",
    "\n",
    "    # Adding the output layer\n",
    "    regressor.add(Dense(units=1))\n",
    "\n",
    "    # Compiling the RNN\n",
    "    # instead of adam we could also have used rmsprop as the optimizer\n",
    "    # This is a regression problem so we use mean_squared_error\n",
    "    # In case of classification we could have used binary cross entropy or categorical cross entropy\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Fitting the RNN to the Training set\n",
    "    regressor.fit(x_train, y_train, epochs=RNN_epochs, batch_size=32)\n",
    "\n",
    "    # Getting the test index values\n",
    "    dataset_total = dataset.iloc[0:, pos:(pos + 1)]\n",
    "    cdataset_total = dataset_total.columns.tolist()\n",
    "\n",
    "    dataset_total = dataset_total[cdataset_total[0]]\n",
    "\n",
    "    # Preparing the inputs\n",
    "    inputs = dataset_total[len(dataset_total) - len(testing_set) - f_param:].values\n",
    "    inputs = inputs.reshape(-1, 1)\n",
    "    inputs = sc.transform(inputs)\n",
    "\n",
    "    X_test = []\n",
    "\n",
    "    for i in range(f_param, (len(testing_set) + f_param)):\n",
    "        X_test.append(inputs[i - f_param:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    predicted_stock_price = regressor.predict(X_test)\n",
    "    predicted_stock_price = sc.inverse_transform(predicted_stock_price)  # exporting data\n",
    "    ts = np.reshape(testing_set, (1, len(testing_set)))\n",
    "    ps = np.reshape(predicted_stock_price, (1, len(predicted_stock_price)))\n",
    "    df = pd.DataFrame(list(zip(list(ts[0][0:]), list(ps[0][0:]))), columns=['real', 'prediction'])\n",
    "    df.to_csv(\"data/Prediction:_\" + str(cols[pos]) + \".csv\")\n",
    "    real_stock_price = testing_set  # exporting graph\n",
    "    plt.plot(real_stock_price, color='red', label='Real Index')\n",
    "    plt.plot(predicted_stock_price, color='blue', label='Predicted Index')\n",
    "    plt.title('Prediction: ' + str(cols[pos]))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Index')\n",
    "    plt.legend()\n",
    "    plt.savefig('data/Magnified_Prediction_Chart:_' + str(cols[pos]) + '.png')\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "    plt.plot([0], [0])\n",
    "    plt.plot(real_stock_price, color='red', label='Real Index')\n",
    "    plt.plot(predicted_stock_price, color='blue', label='Predicted Index')\n",
    "    plt.title('Prediction: ' + str(cols[pos]))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Index')\n",
    "    plt.legend()\n",
    "    plt.savefig('data/Real_Prediction_Chart:_' + str(cols[pos]) + '.png')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(cols) - 2):\n",
    "    predict(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
